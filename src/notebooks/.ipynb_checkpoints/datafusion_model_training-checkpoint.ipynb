{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ebe43dd-8f70-417d-aab9-85d167fe35b9",
   "metadata": {},
   "source": [
    "# Data fusion model training\n",
    "\n",
    "This notebook is used to train the logistic regression models used to predict surface water.\n",
    "\n",
    "The output of these are coeffiecients that should be used within the Earth Engine scritps to apply the logistic regressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b07fbb-fd48-46d5-bbff-a5cbd890b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import datetime\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe1b7cd-ce87-4a82-9f45-f24165120a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef56d70-52da-45bc-b9cc-e71a6d5a874d",
   "metadata": {},
   "source": [
    "## Read in Sen1Floods11 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d80bd-3e2f-4b77-a74f-36ea6a71e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to the path where S1Floods11 data is located\n",
    "parent_dir = Path(\"sen1floods11/v1.1/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b60c72-c978-4a94-b611-9fef7ddacaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "flood_dir = parent_dir / \"flood_events\"\n",
    "handlabel_dir = flood_dir / \"HandLabeled\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0064d2be-5487-42ee-adac-1a1d0160fbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_dir = handlabel_dir / \"S1Hand\"\n",
    "s2_dir = handlabel_dir / \"S2Hand\"\n",
    "label_dir = handlabel_dir / \"LabelHand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d7c8f2-9ea2-484c-9590-5a7916d28534",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_files = s1_dir.glob(\"*.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4515547-60c6-4147-bf1d-265655623066",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [\"_\".join(f.name.split(\"_\")[0:2]) for f in s1_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa4e62-9e11-45b2-9b17-280b2f1c19e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify pairs of S1, S2, and label images\n",
    "img_pairs = [\n",
    "    (s1_dir / f\"{id}_S1Hand.tif\", s2_dir / f\"{id}_S2Hand.tif\", label_dir / f\"{id}_LabelHand.tif\")\n",
    "    for id in ids\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf612ab-2598-418c-8f5f-35e157a6bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to efficiently calculate the std deviation for a moving window\n",
    "def window_stdev(X, window_size):\n",
    "    r,c = X.shape\n",
    "    X+=np.random.rand(r,c)*1e-6\n",
    "    c1 = ndimage.uniform_filter(X, window_size, mode='reflect')\n",
    "    c2 = ndimage.uniform_filter(X*X, window_size, mode='reflect')\n",
    "    return np.sqrt(c2 - c1*c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86946e37-ae94-4db8-b419-250451d3e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# window size for the \n",
    "window_size = 9\n",
    "\n",
    "# loop over all image pairs\n",
    "for i,img_pair in enumerate(img_pairs):\n",
    "    s1_img, s2_img, label_img = img_pair\n",
    "    \n",
    "    # read the data\n",
    "    s1_da = rioxarray.open_rasterio(s1_img)\n",
    "    s2_da = rioxarray.open_rasterio(s2_img)\n",
    "    label_da = rioxarray.open_rasterio(label_img)\n",
    "\n",
    "    s1_da[\"band\"] = list(s1_da.attrs[\"long_name\"])\n",
    "\n",
    "    s2_da[\"band\"] = list(s2_da.attrs[\"long_name\"])\n",
    "    s2_da = s2_da.isel(band=[1,2,3,7,11,12]) / 10000.\n",
    "\n",
    "    s1_ds = s1_da.to_dataset(dim=\"band\")\n",
    "    s2_ds = s2_da.to_dataset(dim=\"band\")\n",
    "    label_ds = label_da[0,:,:].to_dataset(name=\"label\")\n",
    "\n",
    "    label_ds[\"x\"] = s1_ds[\"x\"]\n",
    "    label_ds[\"y\"] = s1_ds[\"y\"]\n",
    "\n",
    "    # merge all of the individual sensors into one dataset\n",
    "    ds = xr.merge([s1_ds, s2_ds, label_ds])\n",
    "    \n",
    "    # calculate moving window statistics for SAR bands\n",
    "    ds['VV_mean'] = (('y', 'x'), ndimage.uniform_filter(ds['VV'].values, size=window_size))\n",
    "    ds['VH_mean'] = (('y', 'x'), ndimage.uniform_filter(ds['VH'].values, size=window_size))\n",
    "    ds['VV_stdDev'] = (('y', 'x'), window_stdev(ds['VV'].values, window_size))\n",
    "    ds['VH_stdDev'] = (('y', 'x'), window_stdev(ds['VH'].values, window_size))\n",
    "\n",
    "    # convert to a dataframe 1-D structure\n",
    "    df_ = ds.to_dataframe().dropna()\n",
    "    \n",
    "    # append dataframes\n",
    "    if i == 0:\n",
    "        df = df_\n",
    "    else:\n",
    "        df = pd.concat([df,df_],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525a16ff-2985-479d-a1d5-edf0d2d84b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that the data is what is expected\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abeaa54-5788-4360-bc8e-1c9572c1526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a random column to dataframe and sort based on the random column\n",
    "df[\"random\"] = np.random.uniform(size=df.shape[0])\n",
    "df.sort_values(\"random\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d43645-a879-4778-8b69-3adc76bfd66d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optionally save dataframe to parquet file to prevent having to process again\n",
    "df.to_parquet(handlabel_dir / f\"s1_s2_label.parq\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c515336b-71e5-4931-9a9d-967a4a1ba734",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(handlabel_dir / \"s1_s2_label.parq\",engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69580a7a-ea58-4b70-bb08-4cc81243c930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select rows where the label is valid (gt 0)\n",
    "df_sel = df.loc[df[\"label\"]>=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f449240e-133e-463d-adf1-be3a851908f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate additional features used for model\n",
    "df_sel[\"VVVH\"] = (df_sel[\"VV\"] / df_sel[\"VH\"])\n",
    "\n",
    "df_sel['mndwi'] = (df_sel['B3'] - df_sel['B11']) / (df_sel['B3'] + df_sel['B11'])\n",
    "df_sel['ndvi'] = (df_sel['B8'] - df_sel['B4']) / (df_sel['B8'] + df_sel['B4'])\n",
    "\n",
    "df_sel.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50c953-379c-4f77-accf-c719d06283df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of samples per label class\n",
    "hist,bins = np.histogram(df_sel['label'],bins=[-1,0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9376d55c-96f4-4540-9e00-c1e07d784195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get extract out land and water samples\n",
    "# subsample the land samples to equal the water samples\n",
    "df_land = df_sel.query('label == 0').sample(hist[-1])\n",
    "df_water = df_sel.query('label == 1')\n",
    "\n",
    "# merge the two dataframes back together\n",
    "df_all = pd.concat([df_land,df_water], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b090d9f8-9f09-4972-9be9-2ec0e2820525",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5420aa0e-129b-431b-8c67-32ca980ed926",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bddd9a-a71a-47e7-9064-a1ad29431bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a logistic regression object\n",
    "clf = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    tol=1e-6,\n",
    "    multi_class='ovr',\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99dea09-90ed-4eea-ae20-2942695c8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract out the labels \n",
    "y = df_all[\"label\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24917c6f-db25-4d05-b8de-0a6d17246c5e",
   "metadata": {},
   "source": [
    "### SAR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefbff7b-ac38-4d4f-8c92-34736231c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract SAR features\n",
    "X_sar = df_all[[\"VV\", \"VH\", 'VV_mean','VV_stdDev','VH_mean','VH_stdDev', 'VVVH']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdfc976-94d0-4ca9-9712-10ce34d97c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing\n",
    "X_train_sar, X_test_sar, y_train_sar, y_test_sar = train_test_split(X_sar, y, test_size=0.33, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba697cf-1f88-4e4c-a800-aeaebb4e307e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold object\n",
    "skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05133a-eaec-46cb-8dbf-b01d94f1957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_kfold_training = dict()\n",
    "\n",
    "# loop through the KFolds\n",
    "# train and assess accuracy per iteration\n",
    "for k, (train, test) in enumerate(skf.split(X_train_sar, y_train_sar)):\n",
    "    clf_fitted = clf.fit(X_train_sar.iloc[train],y_train_sar.iloc[train])\n",
    "    acc = clf_fitted.score(X_train_sar.iloc[test],y_train_sar.iloc[test])\n",
    "        \n",
    "    sar_kfold_training[k] = dict(model=clf_fitted, score=acc,training_idx=train, testing_idx=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9ed780-94ff-4694-a760-5bb2a53d8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_kfold_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfb2efd-2666-4c29-8874-ba38ecc5ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the iteration with best score\n",
    "scores = np.array([sar_kfold_training[i]['score'] for i in range(5)])\n",
    "best_idx = np.argmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cfd781-2f02-4d22-bebb-2651c781053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract out the best model\n",
    "sar_best_model = sar_kfold_training[best_idx]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b30db46-6b4e-4d26-aeb7-d329907e2a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%0.4f accuracy with a standard deviation of %0.4f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95bc1a5-4bc2-494b-ae00-21191659c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using the best model on the hold-out testing data\n",
    "y_pred_sar = sar_best_model.predict(X_test_sar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544ad495-45fa-455f-89c7-a3f42bc56385",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_sar,y_pred_sar))\n",
    "print(\"F1-score:\",metrics.f1_score(y_test_sar,y_pred_sar,average='weighted'))\n",
    "cm = metrics.confusion_matrix(y_test_sar,y_pred_sar,normalize=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0da26d-fe23-4062-863b-d0e53499e62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387349ac-90c4-4341-af69-e36897b406a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_best_model.coef_["
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72fe827-6809-4abd-a895-d89a80b54593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the coefficients\n",
    "sar_coeffs = {col:sar_best_model.coef_[0,i] for i,col in enumerate(X_sar.columns)}\n",
    "sar_coeffs['constant'] = sar_best_model.intercept_[0]\n",
    "\n",
    "sar_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d262d737-2b6b-4777-afad-d7d9a1391786",
   "metadata": {},
   "source": [
    "### Optical model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99889727-bd60-4f28-8fc7-92a27646192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract optical sensor features\n",
    "X_opt = df_all[[\"B2\",\"B3\",\"B4\",\"B8\",\"B11\",\"B12\",'mndwi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a299a030-c666-41e3-b301-32acadaf48d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing\n",
    "X_train_opt, X_test_opt, y_train_opt, y_test_opt = train_test_split(X_opt, y, test_size=0.33, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7214d-6020-4662-86cc-e39656810e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_kfold_training =dict()\n",
    "\n",
    "# loop through the KFolds\n",
    "# train and assess accuracy per iteration\n",
    "for k, (train, test) in enumerate(skf.split(X_train_opt, y_train_opt)):\n",
    "    # print(train)\n",
    "    clf_fitted = clf.fit(X_train_opt.iloc[train],y_train_opt.iloc[train])\n",
    "    acc = clf_fitted.score(X_train_opt.iloc[test],y_train_opt.iloc[test])\n",
    "    \n",
    "#     y_pred_sar = rf_sar.predict(X_test_sar)\n",
    "    \n",
    "    opt_kfold_training[k] = dict(model=clf_fitted, score=acc,training_idx=train, testing_idx=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10868a48-a3f4-44c5-aa7b-ad5daaaad2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_kfold_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fba1e6-aa44-4c9f-ad9d-b4d30710566c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the iteration with best score\n",
    "scores = np.array([opt_kfold_training[i]['score'] for i in range(5)])\n",
    "best_idx = np.argmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06ff13e-9671-41f8-9c56-81b7986b0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract out the best model\n",
    "opt_best_model = opt_kfold_training[best_idx]['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e5731c-7b7c-4fbf-8b23-bce62bd5cf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%0.4f accuracy with a standard deviation of %0.4f\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86eaf2-4745-4199-aa80-624e3444d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict using the best model on the hold-out testing data\n",
    "y_pred_opt = opt_best_model.predict(X_test_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac6304-e86e-4c21-8b08-aacd6026e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_opt,y_pred_opt))\n",
    "print(\"F1-score:\",metrics.f1_score(y_test_opt,y_pred_opt,average='weighted'))\n",
    "cm = metrics.confusion_matrix(y_test_opt,y_pred_opt,normalize=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884d7a17-b13f-4d84-8657-511844b10fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b45c70-4301-4060-8ce5-23bcc34b7053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the coefficients\n",
    "opt_coeffs = {col:opt_best_model.coef_[0,i] for i,col in enumerate(X_opt.columns)}\n",
    "opt_coeffs['constant'] = opt_best_model.intercept_[0]\n",
    "\n",
    "opt_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766b13f5-2b3c-47c7-810a-261197f5b145",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (geo-ml)",
   "language": "python",
   "name": "geo-ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
